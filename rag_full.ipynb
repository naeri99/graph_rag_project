{
 "cells": [
  {
   "cell_type": "code",
   "id": "dbc9d8c8-1cf0-4528-aad0-c01f1fb25086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:34.539006535Z",
     "start_time": "2025-11-25T00:23:33.778980259Z"
    }
   },
   "source": [
    "from tools import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import tools \n",
    "from typing import List, Dict, Tuple\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d92dd57e-d37e-4859-abdb-0a8a99333c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:34.594391226Z",
     "start_time": "2025-11-25T00:23:34.539778211Z"
    }
   },
   "source": [
    "stats = tools.clear_all_graph_data()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‘ï¸  Starting to clear all graph data...\n",
      "   Deleting all relationships...\n",
      "   Deleting all nodes...\n",
      "   Cleaning up GDS graphs...\n",
      "   - No 'entity' graph to drop\n",
      "   Dropping all indexes...\n",
      "   Dropping all constraints...\n",
      "âœ… Graph cleanup completed!\n",
      "   - Deleted 260 relationships\n",
      "   - Deleted 42 nodes\n",
      "   - Remaining nodes: 0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e2e4999c-e98d-499e-89d5-e7d1730e7a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:37.324773670Z",
     "start_time": "2025-11-25T00:23:34.811412070Z"
    }
   },
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/1727/pg1727.txt\"\n",
    "response = requests.get(url)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a9335794-0cc6-4d98-b10a-9f7d4b5c0c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:37.433831629Z",
     "start_time": "2025-11-25T00:23:37.383747754Z"
    }
   },
   "source": [
    "def chunk_into_books(text: str) -> List[str]:\n",
    "    return (\n",
    "        text.split(\"PREFACE TO FIRST EDITION\")[2]\n",
    "        .split(\"FOOTNOTES\")[0]\n",
    "        .strip()\n",
    "        .split(\"\\nBOOK\")[1:]\n",
    "    )\n",
    "\n",
    "books = chunk_into_books(response.text)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "eddeadc3-e491-49ba-8af7-f38fdfd8e3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:37.755165377Z",
     "start_time": "2025-11-25T00:23:37.434498885Z"
    }
   },
   "source": [
    "token_count = [num_tokens_from_string(el) for el in books]\n",
    "print(\n",
    "    f\"\"\"There are {len(token_count)} books with token sizes:\n",
    "- avg {sum(token_count) / len(token_count)}\n",
    "- min {min(token_count)}\n",
    "- max {max(token_count)}\n",
    "\"\"\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 books with token sizes:\n",
      "- avg 6515.208333333333\n",
      "- min 4459\n",
      "- max 10760\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d74c7143-2357-4f05-abc6-b6f18a229cc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:37.803697959Z",
     "start_time": "2025-11-25T00:23:37.755847076Z"
    }
   },
   "source": [
    "chunked_books = [chunk_text(book, 1000, 40) for book in books]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "7a85a1bc-c2ae-41b7-87be-9b6d3ac52079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:37.854458889Z",
     "start_time": "2025-11-25T00:23:37.804347299Z"
    }
   },
   "source": [
    "len(chunked_books[0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "cd158eb0-f79d-4746-bd18-856feb1ebe75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:23:50.884995308Z",
     "start_time": "2025-11-25T00:23:50.878227816Z"
    }
   },
   "source": [
    "from typing import List, Dict, Tuple\n",
    "\n",
    "ENTITY_TYPES = \"PERSON,ORGANIZATION,LOCATION,GOD,EVENT,CREATURE,WEAPON_OR_TOOL\"\n",
    "\n",
    "def extract_entities(text: str) -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Extract entities and relationships from text using Bedrock\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (entities, relationships) as lists of dictionaries\n",
    "    \"\"\"\n",
    "    # Construct prompt\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": tools.create_extraction_prompt(ENTITY_TYPES, text)}\n",
    "    ]\n",
    "    \n",
    "    # Make the LLM call using Bedrock (model parameter is ignored)\n",
    "    output = tools.chat(messages, model=\"gpt-4o\")  # Will use Bedrock instead\n",
    "    \n",
    "    # Parse output and return both entities and relationships\n",
    "    return tools.parse_extraction_output(output)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "f23e32ad-1cc6-44cc-aa06-d3d142cdbfe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:24:00.375069231Z",
     "start_time": "2025-11-25T00:23:51.443298263Z"
    }
   },
   "source": [
    "number_of_books = 1\n",
    "for book_i, book in enumerate(\n",
    "    tqdm(chunked_books[:number_of_books], desc=\"Processing Books\")\n",
    "):\n",
    "    for chunk_i, chunk in enumerate(tqdm(book, desc=f\"Book {book_i}\", leave=False)):\n",
    "        nodes, relationships = extract_entities(chunk)\n",
    "        neo4j_driver.execute_query(\n",
    "            tools.import_nodes_query,\n",
    "            data=nodes,\n",
    "            book_id=book_i,\n",
    "            text=chunk,\n",
    "            chunk_id=chunk_i,\n",
    "        )\n",
    "\n",
    "        neo4j_driver.execute_query(\n",
    "            tools.import_relationships_query, data=relationships\n",
    "        )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Books:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Book 0:   0%|          | 0/22 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "(\"entity\";MUSE;GOD;Divine being invoked to tell the story of the hero's journey and adventures)\n",
      "|\n",
      "(\"entity\";TROY;LOCATION;Famous town that was sacked by the ingenious hero)\n",
      "|\n",
      "(\"entity\";HYPERION;GOD;Sun-god whose cattle were eaten by the hero's men, leading to their destruction)\n",
      "|\n",
      "(\"entity\";JOVE;GOD;Father deity, referred to as the father of the Muse)\n",
      "|\n",
      "(\"entity\";ULYSSES;PERSON;Ingenious hero who sacked Troy and traveled far and wide, trying to return home to"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Books:   0%|          | 0/1 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "EventStreamError",
     "evalue": "An error occurred (serviceUnavailableException) when calling the ConverseStream operation: Bedrock is unable to process your request.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mEventStreamError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m book_i, book \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\n\u001B[32m      3\u001B[39m     tqdm(chunked_books[:number_of_books], desc=\u001B[33m\"\u001B[39m\u001B[33mProcessing Books\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m ):\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m chunk_i, chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(book, desc=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mBook \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbook_i\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, leave=\u001B[38;5;28;01mFalse\u001B[39;00m)):\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m         nodes, relationships = \u001B[43mextract_entities\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m         neo4j_driver.execute_query(\n\u001B[32m      8\u001B[39m             tools.import_nodes_query,\n\u001B[32m      9\u001B[39m             data=nodes,\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m             chunk_id=chunk_i,\n\u001B[32m     13\u001B[39m         )\n\u001B[32m     15\u001B[39m         neo4j_driver.execute_query(\n\u001B[32m     16\u001B[39m             tools.import_relationships_query, data=relationships\n\u001B[32m     17\u001B[39m         )\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mextract_entities\u001B[39m\u001B[34m(text)\u001B[39m\n\u001B[32m     16\u001B[39m messages = [\n\u001B[32m     17\u001B[39m     {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: tools.create_extraction_prompt(ENTITY_TYPES, text)}\n\u001B[32m     18\u001B[39m ]\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Make the LLM call using Bedrock (model parameter is ignored)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m output = \u001B[43mtools\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mgpt-4o\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Will use Bedrock instead\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Parse output and return both entities and relationships\u001B[39;00m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m tools.parse_extraction_output(output)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/graph_rag_project/utils_strand.py:183\u001B[39m, in \u001B[36mchat\u001B[39m\u001B[34m(messages, model, model_id, temperature, **kwargs)\u001B[39m\n\u001B[32m    180\u001B[39m     message = \u001B[38;5;28mstr\u001B[39m(messages)\n\u001B[32m    182\u001B[39m \u001B[38;5;66;03m# Always use Bedrock\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m183\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mchat_bedrock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/graph_rag_project/utils_strand.py:219\u001B[39m, in \u001B[36mchat_bedrock\u001B[39m\u001B[34m(message, model_id, temperature)\u001B[39m\n\u001B[32m    217\u001B[39m     result = temp_agent(message)\n\u001B[32m    218\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m     result = \u001B[43mstrands_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m \u001B[38;5;66;03m# Extract text from AgentResult if needed\u001B[39;00m\n\u001B[32m    222\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(result, \u001B[33m'\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m'\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/agent/agent.py:408\u001B[39m, in \u001B[36mAgent.__call__\u001B[39m\u001B[34m(self, prompt, **kwargs)\u001B[39m\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ThreadPoolExecutor() \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[32m    407\u001B[39m     future = executor.submit(execute)\n\u001B[32m--> \u001B[39m\u001B[32m408\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/concurrent/futures/_base.py:456\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    454\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    455\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    458\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/concurrent/futures/thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001B[39m, in \u001B[36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001B[39m\u001B[34m(*func_args, **func_kwargs)\u001B[39m\n\u001B[32m    169\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    170\u001B[39m     token = context.attach(otel_context)\n\u001B[32m--> \u001B[39m\u001B[32m171\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    173\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/agent/agent.py:404\u001B[39m, in \u001B[36mAgent.__call__.<locals>.execute\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    403\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexecute\u001B[39m() -> AgentResult:\n\u001B[32m--> \u001B[39m\u001B[32m404\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43masyncio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minvoke_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/asyncio/runners.py:195\u001B[39m, in \u001B[36mrun\u001B[39m\u001B[34m(main, debug, loop_factory)\u001B[39m\n\u001B[32m    191\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    192\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    194\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001B[38;5;28;01mas\u001B[39;00m runner:\n\u001B[32m--> \u001B[39m\u001B[32m195\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrunner\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/asyncio/runners.py:118\u001B[39m, in \u001B[36mRunner.run\u001B[39m\u001B[34m(self, coro, context)\u001B[39m\n\u001B[32m    116\u001B[39m \u001B[38;5;28mself\u001B[39m._interrupt_count = \u001B[32m0\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m118\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_until_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.CancelledError:\n\u001B[32m    120\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._interrupt_count > \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/asyncio/base_events.py:691\u001B[39m, in \u001B[36mBaseEventLoop.run_until_complete\u001B[39m\u001B[34m(self, future)\u001B[39m\n\u001B[32m    688\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m future.done():\n\u001B[32m    689\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mEvent loop stopped before Future completed.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m691\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/agent/agent.py:436\u001B[39m, in \u001B[36mAgent.invoke_async\u001B[39m\u001B[34m(self, prompt, **kwargs)\u001B[39m\n\u001B[32m    411\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Process a natural language prompt through the agent's event loop.\u001B[39;00m\n\u001B[32m    412\u001B[39m \n\u001B[32m    413\u001B[39m \u001B[33;03mThis method implements the conversational interface with multiple input patterns:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    433\u001B[39m \u001B[33;03m        - state: The final state of the event loop\u001B[39;00m\n\u001B[32m    434\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    435\u001B[39m events = \u001B[38;5;28mself\u001B[39m.stream_async(prompt, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m436\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m events:\n\u001B[32m    437\u001B[39m     _ = event\n\u001B[32m    439\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(AgentResult, event[\u001B[33m\"\u001B[39m\u001B[33mresult\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/agent/agent.py:581\u001B[39m, in \u001B[36mAgent.stream_async\u001B[39m\u001B[34m(self, prompt, **kwargs)\u001B[39m\n\u001B[32m    578\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    579\u001B[39m     events = \u001B[38;5;28mself\u001B[39m._run_loop(messages, invocation_state=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m events:\n\u001B[32m    582\u001B[39m         event.prepare(invocation_state=kwargs)\n\u001B[32m    584\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m event.is_callback_event:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/agent/agent.py:619\u001B[39m, in \u001B[36mAgent._run_loop\u001B[39m\u001B[34m(self, messages, invocation_state)\u001B[39m\n\u001B[32m    617\u001B[39m \u001B[38;5;66;03m# Execute the event loop cycle with retry logic for context limits\u001B[39;00m\n\u001B[32m    618\u001B[39m events = \u001B[38;5;28mself\u001B[39m._execute_event_loop_cycle(invocation_state)\n\u001B[32m--> \u001B[39m\u001B[32m619\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m events:\n\u001B[32m    620\u001B[39m     \u001B[38;5;66;03m# Signal from the model provider that the message sent by the user should be redacted,\u001B[39;00m\n\u001B[32m    621\u001B[39m     \u001B[38;5;66;03m# likely due to a guardrail.\u001B[39;00m\n\u001B[32m    622\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    623\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(event, ModelStreamChunkEvent)\n\u001B[32m    624\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m event.chunk\n\u001B[32m    625\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m event.chunk.get(\u001B[33m\"\u001B[39m\u001B[33mredactContent\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    626\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m event.chunk[\u001B[33m\"\u001B[39m\u001B[33mredactContent\u001B[39m\u001B[33m\"\u001B[39m].get(\u001B[33m\"\u001B[39m\u001B[33mredactUserContentMessage\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    627\u001B[39m     ):\n\u001B[32m    628\u001B[39m         \u001B[38;5;28mself\u001B[39m.messages[-\u001B[32m1\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m] = [\n\u001B[32m    629\u001B[39m             {\u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(event.chunk[\u001B[33m\"\u001B[39m\u001B[33mredactContent\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mredactUserContentMessage\u001B[39m\u001B[33m\"\u001B[39m])}\n\u001B[32m    630\u001B[39m         ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/agent/agent.py:658\u001B[39m, in \u001B[36mAgent._execute_event_loop_cycle\u001B[39m\u001B[34m(self, invocation_state)\u001B[39m\n\u001B[32m    652\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    653\u001B[39m     \u001B[38;5;66;03m# Execute the main event loop cycle\u001B[39;00m\n\u001B[32m    654\u001B[39m     events = event_loop_cycle(\n\u001B[32m    655\u001B[39m         agent=\u001B[38;5;28mself\u001B[39m,\n\u001B[32m    656\u001B[39m         invocation_state=invocation_state,\n\u001B[32m    657\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m658\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m events:\n\u001B[32m    659\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m event\n\u001B[32m    661\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ContextWindowOverflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    662\u001B[39m     \u001B[38;5;66;03m# Try reducing the context size and retrying\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/event_loop/event_loop.py:110\u001B[39m, in \u001B[36mevent_loop_cycle\u001B[39m\u001B[34m(agent, invocation_state)\u001B[39m\n\u001B[32m    107\u001B[39m invocation_state[\u001B[33m\"\u001B[39m\u001B[33mevent_loop_cycle_span\u001B[39m\u001B[33m\"\u001B[39m] = cycle_span\n\u001B[32m    109\u001B[39m model_events = _handle_model_execution(agent, cycle_span, cycle_trace, invocation_state, tracer)\n\u001B[32m--> \u001B[39m\u001B[32m110\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m model_event \u001B[38;5;129;01min\u001B[39;00m model_events:\n\u001B[32m    111\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model_event, ModelStopReason):\n\u001B[32m    112\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m model_event\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/event_loop/event_loop.py:316\u001B[39m, in \u001B[36m_handle_model_execution\u001B[39m\u001B[34m(agent, cycle_span, cycle_trace, invocation_state, tracer)\u001B[39m\n\u001B[32m    314\u001B[39m                 \u001B[38;5;28;01myield\u001B[39;00m EventLoopThrottleEvent(delay=current_delay)\n\u001B[32m    315\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m                 \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    319\u001B[39m     \u001B[38;5;66;03m# Add message in trace and mark the end of the stream messages trace\u001B[39;00m\n\u001B[32m    320\u001B[39m     stream_trace.add_message(message)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/event_loop/event_loop.py:264\u001B[39m, in \u001B[36m_handle_model_execution\u001B[39m\u001B[34m(agent, cycle_span, cycle_trace, invocation_state, tracer)\u001B[39m\n\u001B[32m    261\u001B[39m tool_specs = agent.tool_registry.get_all_tool_specs()\n\u001B[32m    263\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m264\u001B[39m     \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m stream_messages(agent.model, agent.system_prompt, agent.messages, tool_specs):\n\u001B[32m    265\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m event\n\u001B[32m    267\u001B[39m     stop_reason, message, usage, metrics = event[\u001B[33m\"\u001B[39m\u001B[33mstop\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/event_loop/streaming.py:351\u001B[39m, in \u001B[36mstream_messages\u001B[39m\u001B[34m(model, system_prompt, messages, tool_specs)\u001B[39m\n\u001B[32m    348\u001B[39m messages = remove_blank_messages_content_text(messages)\n\u001B[32m    349\u001B[39m chunks = model.stream(messages, tool_specs \u001B[38;5;28;01mif\u001B[39;00m tool_specs \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, system_prompt)\n\u001B[32m--> \u001B[39m\u001B[32m351\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m process_stream(chunks):\n\u001B[32m    352\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m event\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/event_loop/streaming.py:308\u001B[39m, in \u001B[36mprocess_stream\u001B[39m\u001B[34m(chunks)\u001B[39m\n\u001B[32m    305\u001B[39m usage: Usage = Usage(inputTokens=\u001B[32m0\u001B[39m, outputTokens=\u001B[32m0\u001B[39m, totalTokens=\u001B[32m0\u001B[39m)\n\u001B[32m    306\u001B[39m metrics: Metrics = Metrics(latencyMs=\u001B[32m0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m308\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunks:\n\u001B[32m    309\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m ModelStreamChunkEvent(chunk=chunk)\n\u001B[32m    310\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mmessageStart\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m chunk:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/models/bedrock.py:625\u001B[39m, in \u001B[36mBedrockModel.stream\u001B[39m\u001B[34m(self, messages, tool_specs, system_prompt, tool_choice, **kwargs)\u001B[39m\n\u001B[32m    621\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m event\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m task\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/asyncio/threads.py:25\u001B[39m, in \u001B[36mto_thread\u001B[39m\u001B[34m(func, *args, **kwargs)\u001B[39m\n\u001B[32m     23\u001B[39m ctx = contextvars.copy_context()\n\u001B[32m     24\u001B[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m loop.run_in_executor(\u001B[38;5;28;01mNone\u001B[39;00m, func_call)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/concurrent/futures/thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001B[39m, in \u001B[36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001B[39m\u001B[34m(*func_args, **func_kwargs)\u001B[39m\n\u001B[32m    169\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    170\u001B[39m     token = context.attach(otel_context)\n\u001B[32m--> \u001B[39m\u001B[32m171\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    173\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/models/bedrock.py:743\u001B[39m, in \u001B[36mBedrockModel._stream\u001B[39m\u001B[34m(self, callback, messages, tool_specs, system_prompt, tool_choice)\u001B[39m\n\u001B[32m    734\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    735\u001B[39m             e.response[\u001B[33m\"\u001B[39m\u001B[33mError\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mCode\u001B[39m\u001B[33m\"\u001B[39m] == \u001B[33m\"\u001B[39m\u001B[33mValidationException\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    736\u001B[39m             \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mwith on-demand throughput isnâ€™t supported\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m error_message\n\u001B[32m    737\u001B[39m         ):\n\u001B[32m    738\u001B[39m             e.add_note(\n\u001B[32m    739\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mâ”” For more information see \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    740\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mhttps://strandsagents.com/latest/user-guide/concepts/model-providers/amazon-bedrock/#on-demand-throughput-isnt-supported\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    741\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m743\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    745\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    746\u001B[39m     callback()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/strands/models/bedrock.py:664\u001B[39m, in \u001B[36mBedrockModel._stream\u001B[39m\u001B[34m(self, callback, messages, tool_specs, system_prompt, tool_choice)\u001B[39m\n\u001B[32m    662\u001B[39m \u001B[38;5;66;03m# Track tool use events to fix stopReason for streaming responses\u001B[39;00m\n\u001B[32m    663\u001B[39m has_tool_use = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m664\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    665\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    666\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n\u001B[32m    667\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrace\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m    668\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mguardrail\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrace\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m    669\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    670\u001B[39m \u001B[43m        \u001B[49m\u001B[43mguardrail_data\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrace\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mguardrail\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/botocore/eventstream.py:592\u001B[39m, in \u001B[36mEventStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    590\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    591\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_generator:\n\u001B[32m--> \u001B[39m\u001B[32m592\u001B[39m         parsed_event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parse_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    593\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m parsed_event:\n\u001B[32m    594\u001B[39m             \u001B[38;5;28;01myield\u001B[39;00m parsed_event\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/graph/lib/python3.12/site-packages/botocore/eventstream.py:608\u001B[39m, in \u001B[36mEventStream._parse_event\u001B[39m\u001B[34m(self, event)\u001B[39m\n\u001B[32m    606\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parsed_response\n\u001B[32m    607\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m608\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m EventStreamError(parsed_response, \u001B[38;5;28mself\u001B[39m._operation_name)\n",
      "\u001B[31mEventStreamError\u001B[39m: An error occurred (serviceUnavailableException) when calling the ConverseStream operation: Bedrock is unable to process your request.",
      "â”” Bedrock region: ap-northeast-2",
      "â”” Model id: apac.anthropic.claude-sonnet-4-20250514-v1:0"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "3f20b002-4547-47f5-9102-c6ad4f9060ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:14:58.874750991Z",
     "start_time": "2025-11-25T00:14:58.822348713Z"
    }
   },
   "source": [
    "nodes[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'record_type': 'entity',\n",
       " 'entity_name': 'LAERTES',\n",
       " 'entity_type': 'PERSON',\n",
       " 'entity_description': \"Man who respected Euryclea as much as his own wedded wife but did not take her to his bed for fear of his wife's resentment\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "353c338d-e29b-4565-8ac9-f01f480721c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:14:59.770912111Z",
     "start_time": "2025-11-25T00:14:59.764376931Z"
    }
   },
   "source": [
    "relationships[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'record_type': 'relationship',\n",
       " 'source_entity': 'LAERTES',\n",
       " 'target_entity': \"LAERTES' WIFE\",\n",
       " 'relationship_description': 'Laertes is married to his wedded wife and fears her resentment',\n",
       " 'relationship_strength': 9}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "67c05004-814c-4d4a-b723-bd69893adc31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:15:22.184368582Z",
     "start_time": "2025-11-25T00:15:22.064311649Z"
    }
   },
   "source": [
    "data, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (:`__Entity__`)\n",
    "    RETURN 'entity' AS type, count(*) AS count\n",
    "    UNION\n",
    "    MATCH ()-[:RELATIONSHIP]->()\n",
    "    RETURN 'relationship' AS type, count(*) AS count\n",
    "    \"\"\"\n",
    ")\n",
    "print([el.data() for el in data])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'entity', 'count': 127}, {'type': 'relationship', 'count': 247}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "81559adb-5ec9-484a-aac2-815c0815a7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:15:28.186197532Z",
     "start_time": "2025-11-25T00:15:28.137425804Z"
    }
   },
   "source": [
    "data, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (n:PERSON)\n",
    "WHERE n.name = \"ORESTES\"\n",
    "RETURN n.description AS description\"\"\"\n",
    ")\n",
    "print([el.data()['description'] for el in data])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"Son of Agamemnon who killed Aegisthus in revenge for his father's murder\", 'Son who would grow up to take revenge on Aegisthus for killing his father Agamemnon', \"Hero whose praises people sing for having killed his father's murderer Aegisthus\"]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d95fa0b-9e60-461d-8dd0-e81e9d648fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': 'TELEMACHUS', 'target': 'ULYSSES', 'countOfRels': 14, 'descriptions': ['Telemachus is the son of Ulysses and declares his father dead and gone', 'Telemachus is the son of Ulysses and heir to those whom his father won', 'Telemachus is the son of Ulysses and heir to his position as chief', \"Telemachus thinks more than ever about his father after Minerva's encouragement\", 'Telemachus is searching for news of his missing father Ulysses', 'Telemachus should go in quest of his father Ulysses who has long been missing', 'Telemachus is the son of Ulysses and thinks about his brave father', 'Telemachus is the son of Ulysses, referred to as his unhappy father', 'Telemachus refers to his absent father Ulysses whose bones lie rotting and at whose cost the banquet is held', \"Telemachus is the son of Ulysses and speaks about his father's absence and ill fate\", 'Telemachus resembles Ulysses about the head and eyes', 'Telemachus is the son of Ulysses and would have been heir to his renown', 'Ulysses is the father of Telemachus', 'Ulysses is the father of Telemachus, though Telemachus wishes he had a different father']}]\n"
     ]
    }
   ],
   "source": [
    "data, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (n:__Entity__)-[:RELATIONSHIP]-(m:__Entity__)\n",
    "WITH n,m, count(*) AS countOfRels\n",
    "ORDER BY countOfRels DESC LIMIT 1\n",
    "MATCH (n)-[r:RELATIONSHIP]-(m)\n",
    "RETURN n.name AS source, m.name AS target, countOfRels, collect(r.description) AS descriptions\n",
    "\"\"\"\n",
    ")\n",
    "print([el.data() for el in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a61d4-11a0-4bc6-8d9f-48d7bdb6f17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Telemachus is the son of Ulysses, bearing a strong physical resemblance to his father about the head and eyes. As a young man grieving for his lost father, Telemachus sits moodily among the suitors who have invaded his house under the pretext of courting his mother Penelope. These chiefs from various islands are consuming his family's resources, causing him great suffering as he thinks about his brave father and hopes for his return, though he publicly declares his father dead.\n",
      "\n",
      "When the goddess Minerva visits him disguised as Mentes, chief of the Taphians, Telemachus serves as a gracious host, welcoming the guest, taking her spear, and providing seating away from the suitors. He speaks privately with Minerva about the cost of the banquet and questions the stranger about their identity and origin. Though he identifies the visitor as Mentes to others, Telemachus knows in his heart that the stranger was actually a goddess. Through this encounter, Minerva emboldens him and gives him counsel about his future actions.\n",
      "\n",
      "Following Minerva's advice, Telemachus begins to assert his authority more boldly. He tells his mother to let the bard Phemius continue singing and declares himself master of the house, confronting the suitors and demanding they depart while asserting his right to be chief in Ithaca. He aspires to rule his own house and those whom Ulysses won for him, and plans to call an assembly to formally address the suitors' behavior.\n",
      "\n",
      "Telemachus was nursed as a baby by the loyal servant Euryclea, who continues to care for him and loves him more than the other women in the household. Despite being told by his mother that he is Ulysses' son, Telemachus sometimes wishes for a different father due to the troubles his father's absence has brought. As he lies in his room at night covered with a woollen fleece, he thinks through his intended voyage to search for news of his missing father, contemplating the counsel that Minerva has given him about taking action against the suitors and reclaiming his rightful place as heir to Ulysses'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:   4%|â–Ž         | 1/28 [00:11<05:01, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " legacy.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "The Achaeans are Greek warriors who fought in the war at Troy and subsequently faced a difficult return journey home. During their return from Troy, the Achaeans suffered various ills inflicted upon them by the goddess Minerva. Among these warriors, Menelaus was notably the last of the Achaeans to successfully make it home from the war.\n",
      "\n",
      "The Achaeans maintain a connection to Telemachus and his household, as Telemachus plans to call them in assembly to address his situation with the suitors. They represent a community that honors fallen heroes, as they would have built a commemorative mound over Ulysses' ashes if he had died honorably in battle rather than disappearing without a trace. This demonstrates their respect for proper burial rites and the commemoration of their fellow warriors who served alongside them in"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:   7%|â–‹         | 2/28 [00:17<03:42,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the Trojan War.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Penelope is the daughter of Icarius and the wife of the missing hero Ulysses, as well as the mother of Telemachus. She finds herself in a difficult position as the object of numerous suitors who are consuming her household's resources, including eating up their livestock, while she remains uncertain about her husband's fate. Penelope tells her son Telemachus that he is the son of Ulysses, but she struggles with the decision of whether to remarry, neither refusing marriage outright nor bringing the matter to a definitive end.\n",
      "\n",
      "In her grief and uncertainty, Penelope sometimes consults soothsayers, questioning them about prophecies that might reveal news of her husband's fate. She is often found mourning her lost husband, as demonstrated when she heard the bard's song from her room upstairs and came down weeping. When her son Telemachus asserts his authority and tells her to busy herself with domestic duties such as her loom and distaff, she complies and goes upstairs to continue mourning.\n",
      "\n",
      "The expectation is that if Ulysses is confirmed dead, Penelope should remarry, and her mind may indeed be set on this course of action. However, her prolonged indecision creates ongoing problems for her household, as the persistent suitors continue to drain the family's resources while awaiting her choice. Throughout this ordeal, Penelope remains devoted to the memory of Ulysses while grappling with the practical necessity of potentially moving forward with a"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  11%|â–ˆ         | 3/28 [00:28<03:53,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " new marriage.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Sparta is a location that serves as an important destination in Telemachus' quest to find news of his missing father Ulysses. According to the guidance provided by the goddess Minerva, Sparta is the second destination where Telemachus should travel, specifically to visit Menelaus who resides there. Minerva will conduct Telemachus to Sparta as part of his journey to seek information about his father's fate. This visit to Menelaus in Sparta represents a crucial step in Telemachus' search for answers, as Menelaus, being one of the Greek warriors who returned from Troy, may possess valuable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  14%|â–ˆâ–        | 4/28 [00:36<03:34,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " knowledge about what happened to Ulysses.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Pylos is a location that serves as the first and primary destination in Telemachus' journey to seek news of his missing father Ulysses. According to the guidance provided by the goddess Minerva, Pylos is where Telemachus should begin his quest, specifically to visit and question Nestor about his father's fate. Minerva will conduct Telemachus to Pylos as the initial step in his search for information about what happened to Ulysses. This visit to Nestor in Pylos represents the starting point of Telemachus' formal investigation into his father's disappearance, as Nestor, being a wise elder and fellow veteran of the Trojan War, may possess valuable knowledge or insights about"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  18%|â–ˆâ–Š        | 5/28 [00:52<04:24, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ulysses' whereabouts.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Mentes is the son of Anchialus and serves as both chief and king of the Taphians. He is a trader who sails with iron cargo and maintains that there was a friendship between his father and Laertes. Mentes was a close friend of Ulysses, having known him before Ulysses sailed to Troy, and he notices the strong resemblance between Telemachus and his father. Unlike others who believe Ulysses is dead, Mentes maintains that Ulysses is still alive.\n",
      "\n",
      "However, the true significance of Mentes in this narrative is that he serves as the disguise chosen by the goddess Minerva when she visits Telemachus. Minerva assumes Mentes' identity completely, presenting herself as this Taphian king and old friend of Ulysses. When Telemachus encounters the stranger, he identifies the visitor as Mentes, though he intuitively knows in his heart that it was actually the goddess in disguise. Through this assumed identity, Minerva is able to approach Telemachus credibly as someone who would have legitimate knowledge of his father and reasonable cause to offer guidance about his situation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  21%|â–ˆâ–ˆâ–       | 6/28 [01:09<04:56, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "The Taphians are a people who are ruled by Mentes, who serves as both their chief and king. This leadership structure becomes significant in the narrative because when the goddess Minerva chooses to disguise herself, she assumes the identity of Mentes and therefore presents herself as the ruler of the Taphians. Through this disguise, Minerva claims authority over the Taphian people as part of her credible persona when visiting and advising Telemachus. The Taphians thus serve as the political and social foundation that legitimizes Mentes' status and, by extension, provides authenticity to Minerva's assumed identity during her divine intervention in Telemachus' story"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  25%|â–ˆâ–ˆâ–Œ       | 7/28 [01:17<04:03, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "The suitors are a group of lordly but shameless and insolent men who have invaded Ulysses' house to court his wife Penelope. These men have taken over the household, occupying benches and seats for their banquets, killing and eating the family's oxen, and making havoc of the estate while feasting at Telemachus' expense. They are described as both noisy and clamorous, creating such a disturbance that hosts must seat guests away from them to avoid annoyance.\n",
      "\n",
      "The suitors spend their time in various leisure activities, playing draughts, listening to the bard Phemius sing while drinking wine, and engaging in singing and dancing that continues until evening before they retire to their own homes. Throughout their stay in the covered cloisters, they pray - each hoping to become Penelope's bedfellow and new husband.\n",
      "\n",
      "Their behavior is characterized as rascally and wasteful, as they consume the household's resources while Penelope remains undecided about remarriage. The suitors represent a significant threat to Telemachus' inheritance and authority, leading to advice that he should remove them by fair means or foul. There is an ominous suggestion that if Ulysses were to return, these suitors would face a short shrift and sorry wedding, implying violent retribution for their presumptuous occupation of his house and pursuit of his wife. Their presence creates the central conflict of the household, as they exploit Penelope's indecision while stea"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  29%|â–ˆâ–ˆâ–Š       | 8/28 [01:34<04:24, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dily depleting the family's wealth and resources.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "The pages are young servants who work alongside the men-servants to attend to the suitors in Ulysses' household. Their duties include helping to wait upon the suitors during their feasts and specifically filling the mixing-bowls with wine and water as part of the banquet service. These pages represent part of the household staff that has been pressed into service to accommodate the demanding presence of the suitors who have taken over the house while"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  32%|â–ˆâ–ˆâ–ˆâ–      | 9/28 [01:39<03:24, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " courting Penelope.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Phemius is a singer and bard who possesses a divine voice and plays the lyre for the assembled company in Ulysses' household. He has been compelled by the suitors to perform for them during their occupation of the house. Phemius' repertoire includes telling the sad tale of the return from Troy and the various ills that the goddess Minerva laid upon the Achaeans during their journey home from war. His beautiful singing voice and musical talents make him a valued entertainer, though his position appears to be somewhat involuntary as he serves at the demand of the suitors rather than by his own choice. Through his performances, Phemius inadvertently causes pain to Penelope when his songs about the Trojan War and its aftermath remind her of her missing husban"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 10/28 [01:57<03:50, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d Ulysses.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Anchialus is the father of Mentes, the chief of the Taphians, and this paternal relationship becomes part of the identity that the goddess Minerva assumes when she disguises herself to visit Telemachus. However, there appears to be some confusion in the descriptions, as Anchialus is also described as Minerva's father, which would make him a divine figure. In this divine capacity, Anchialus had a close relationship with Ulysses, being very fond of the hero. When Ilus, son of Mermerus, refused to give Ulysses poison for his arrows out of fear of the gods, it was Anchialus who provided Ulysses with what he needed. This act of assistance demonstrates Anchialus' favor toward Ulysses and his willingness to help the hero when others would not, likely due to their"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 11/28 [02:05<03:14, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " strong friendship and mutual respect.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Temesa is a destination where Mentes claims to be bound during his voyage, serving as part of his cover story when the goddess Minerva assumes his identity to visit Telemachus. According to this disguise, Mentes is traveling to Temesa with a cargo of iron that he intends to trade for copper. Temesa is described as a place inhabited by men of foreign tongue, indicating it is a distant location where different languages are spoken, making it a plausible destination for international trade. This trading mission to Temesa provides credible justification for Mentes' presence and his need to stop at Telemachus' house during his journey, lending authenticity to Minerva's assumed identity as a traveling merchant and friend of the"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 12/28 [02:14<02:51, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " family.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "Laertes is an old man who now lives in the country with an old woman caring for him in his advanced years. He had a friendship with the father of Mentes, establishing a connection between the families that spans generations. In his earlier years, Laertes purchased the servant Euryclea when she was quite young, paying the substantial price of twenty oxen for her. He treated Euryclea with exceptional respect and kindness, showing her as much consideration as he did his own wedded wife. However, despite this high regard for Euryclea, Laertes maintained appropriate boundaries and did not take her to his bed, being mindful of his wife's potential resentment and maintaining the proper order of his household. This demonstrates Laertes' character as someone who could be both generous and respectful to his servants while remaining faithful"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 13/28 [02:24<02:38, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to his marriage and considerate of his wife's feelings.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "The ship is a vessel that plays a central role in the narrative's travel plans and divine deception. When the goddess Minerva disguises herself as Mentes, she claims ownership of a ship that lies in the harbour Rheithron, using this as part of her credible identity as a traveling merchant. However, since Minerva is actually the one speaking, this ship effectively belongs to her in the context of her assumed identity, and she references needing to return to this vessel as part of maintaining her disguise.\n",
      "\n",
      "Additionally, there is guidance given that Telemachus should obtain the best available ship for his own quest, specifically one that can accommodate a crew of twenty men, to search for news of his missing father Ulysses. This represents the practical vessel that Telemachus will need for his journey to Pylos and Sparta, separate from the ship associated with Minerva's disguised visit. The ship thus serves both as a prop in Minerva's deception and as the means by which Telemachus will embark on his own"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 14/28 [02:32<02:17,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " heroic journey to find his father.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n",
      "The crew represents two distinct groups of twenty men in the narrative. First, there is the crew that Telemachus should assemble to accompany him on his quest to find his father - twenty men who would sail with him to Pylos and Sparta as he searches for news of Ulysses. Second, there is the crew that belongs to Minerva in her disguise as Mentes, who she claims will become impatient if kept waiting too long at the harbor. This second crew serves as part of Minerva's cover story, providing a credible reason for her to limit the length of her visit and maintain the authenticity of her assumed identity as a traveling merchant who must attend to her ship and sailors. Both crews represent the practical necessity of having sufficient manpower to operate ships for long voyages, whether for divine deception or heroic qu"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 15/28 [02:39<01:55,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ests.âš ï¸  Model 'gpt-4o' requested but using Bedrock instead (OpenAI disabled)\n"
     ]
    }
   ],
   "source": [
    "candidates_to_summarize, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (e:__Entity__) WHERE size(e.description) > 1 \n",
    "    RETURN e.name AS entity_name, e.description AS description_list\"\"\"\n",
    ")\n",
    "summaries = []\n",
    "for candidate in tqdm(candidates_to_summarize, desc=\"Summarizing entities\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": tools.get_summarize_prompt(\n",
    "                candidate[\"entity_name\"], candidate[\"description_list\"]\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    summary = chat(messages, model=\"gpt-4o\")\n",
    "    summaries.append({\"entity\": candidate[\"entity_name\"], \"summary\": summary})\n",
    "\n",
    "tools.import_entity_summary(summaries, neo4j_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8646d02-d781-4bc4-8e31-fd18279faefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (n:PERSON)\n",
    "WHERE n.summary IS NULL\n",
    "RETURN n.name AS name\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08cc215-7e34-4a9a-86c9-2ceeea00acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e9949-108a-45f8-baf8-b905f9d235b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (n:PERSON)\n",
    "WHERE n.name = \"ORESTES\"\n",
    "RETURN n.summary AS summary\"\"\")\n",
    "print(summary[0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717f1ba-d95b-439b-9af3-41353cf9e9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad99a2-355c-49f9-be37-5cd886c1b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°©ë²• 2: ë” ì•ˆì „í•œ ë²„ì „\n",
    "\n",
    "def get_person_summary(person_name: str):\n",
    "    \"\"\"Get summary for a specific person from Neo4j\"\"\"\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        MATCH (n:PERSON)\n",
    "        WHERE n.name = $person_name\n",
    "        RETURN n.summary AS summary\n",
    "        \"\"\"\n",
    "        \n",
    "        records, _, _ = tools.neo4j_driver.execute_query(\n",
    "            query, \n",
    "            person_name=person_name\n",
    "        )\n",
    "        \n",
    "        if records and len(records) > 0:\n",
    "            summary = records[0]['summary']\n",
    "            if summary:\n",
    "                return summary\n",
    "            else:\n",
    "                return f\"No summary available for {person_name}\"\n",
    "        else:\n",
    "            return f\"Person '{person_name}' not found in database\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error querying database: {e}\"\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "result = get_person_summary(\"ORESTES\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c1373-7fdd-4712-8d03-4029735af0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rels_to_summarize, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (s:__Entity__)-[r:RELATIONSHIP]-(t:__Entity__)\n",
    "    WHERE id(s) < id(t)\n",
    "    WITH s.name AS source, t.name AS target, \n",
    "           collect(r.description) AS description_list,\n",
    "           count(*) AS count\n",
    "    WHERE count > 1\n",
    "    RETURN source, target, description_list\"\"\"\n",
    ")\n",
    "rel_summaries = []\n",
    "for candidate in tqdm(rels_to_summarize, desc=\"Summarizing relationships\"):\n",
    "    entity_name = f\"{candidate['source']} relationship to {candidate['target']}\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": tools.get_summarize_prompt(\n",
    "                entity_name, candidate[\"description_list\"]\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    summary = chat(messages, model=\"gpt-4o\")\n",
    "    rel_summaries.append({\"source\": candidate[\"source\"], \"target\": candidate[\"target\"], \"summary\": summary})\n",
    "\n",
    "tools.import_rels_summary(summaries, neo4j_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f2d39-cca1-4fea-a5e6-c7481fe12ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (n:__Entity__)-[r:SUMMARIZED_RELATIONSHIP]-(m:__Entity__)\n",
    "WHERE n.name = 'TELEMACHUS' AND m.name = 'MINERVA'\n",
    "RETURN r.summary AS description\n",
    "\"\"\"\n",
    ")\n",
    "print(data[0][\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d59ea-04f4-42da-9a70-fcb3eb967383",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_distribution = tools.calculate_communities(neo4j_driver)\n",
    "print(f\"There are {community_distribution['communityCount']} communities with distribution: {community_distribution['communityDistribution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacaf80-218d-4209-9a68-56c94b003f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_info, _, _ = neo4j_driver.execute_query(tools.community_info_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5d7e9-b95f-4ae4-b391-7b4ef18a9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Finding(BaseModel):\n",
    "    summary: str = Field(description=\"Finding summary\")\n",
    "    explanation: str = Field(description=\"Detailed explanation\")\n",
    "\n",
    "class LiteraryAnalysis(BaseModel):\n",
    "    title: str = Field(description=\"Analysis title\")\n",
    "    summary: str = Field(description=\"Analysis summary\")\n",
    "    rating: float = Field(description=\"Rating score\")\n",
    "    rating_explanation: str = Field(description=\"Rating explanation\")\n",
    "    findings: List[Finding] = Field(description=\"List of findings\")\n",
    "\n",
    "class AdvancedLLM:\n",
    "    \"\"\"ê³ ê¸‰ LLM ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ìž\"\"\"\n",
    "    \n",
    "    def __init__(self, region_name: str = \"us-west-2\"):\n",
    "        self.region_name = region_name\n",
    "        self.model_id = None\n",
    "        self.bedrock_client = self._setup_bedrock_client()\n",
    "        self.llm = self._setup_llm()\n",
    "        self.parser = PydanticOutputParser(pydantic_object=LiteraryAnalysis)\n",
    "    \n",
    "    def _setup_bedrock_client(self):\n",
    "        \"\"\"Bedrock í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\"\"\"\n",
    "        try:\n",
    "            return boto3.client(\n",
    "                service_name='bedrock-runtime',\n",
    "                region_name=self.region_name\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _setup_llm(self, model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\"):\n",
    "        \"\"\"LLM ì„¤ì •\"\"\"\n",
    "        try:\n",
    "            if not self.bedrock_client:\n",
    "                print(\"âŒ Bedrock í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return None\n",
    "            \n",
    "            self.model_id = model_id\n",
    "            return ChatBedrock(\n",
    "                client=self.bedrock_client,\n",
    "                model_id=self.model_id,\n",
    "                model_kwargs={\n",
    "                    \"max_tokens\": 4000,\n",
    "                    \"temperature\": 0.15,\n",
    "                    \"top_p\": 0.9,\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_minerva_telemachus_analysis(self, summary):\n",
    "        \"\"\"ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ìƒì„±\"\"\"\n",
    "        if not self.llm:\n",
    "            return None\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        ë‹¤ìŒ ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”:\n",
    "    \n",
    "        ì»¤ë®¤ë‹ˆí‹° ìš”ì•½: {summary}\n",
    "    \n",
    "        {self.parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            message = HumanMessage(content=prompt)\n",
    "            response = self.llm([message])\n",
    "            parsed_response = self.parser.parse(response.content)\n",
    "            return parsed_response.dict()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1954600-7d6b-4084-b2ff-181667a81942",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=AdvancedLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8fa58-484b-4b03-b52a-e9fa501e7ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56e5a4-ee1c-4b9f-83ff-69deebc456c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = []\n",
    "for community in tqdm(community_info, desc=\"Summarizing communities\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": tools.get_summarize_community_prompt(\n",
    "                community[\"nodes\"], community[\"rels\"]\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    summary = chat(messages, model=\"gpt-4o\")\n",
    "    re_summary=llm.generate_minerva_telemachus_analysis(summary)\n",
    "    communities.append(\n",
    "        {\n",
    "            \"community\": re_summary,\n",
    "            \"communityId\": community[\"communityId\"],\n",
    "            \"nodes\": [el[\"id\"] for el in community[\"nodes\"]],\n",
    "        }\n",
    "    )\n",
    "\n",
    "neo4j_driver.execute_query(tools.import_community_query, data=communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888d46c-7261-4231-b62b-2fedec5f0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver.execute_query(\"\"\"UNWIND $data AS row\n",
    "                            MERGE (c:__Community__ {communityId: row.communityId})\n",
    "                            SET c.title = row.community.title,\n",
    "                                c.summary = row.community.summary,\n",
    "                                c.rating = row.community.rating,\n",
    "                                c.rating_explanation = row.community.rating_explanation\n",
    "                            WITH c, row\n",
    "                            UNWIND row.nodes AS node\n",
    "                            MERGE (n:__Entity__ {name: node})\n",
    "                            MERGE (n)-[:IN_COMMUNITY]->(c)\"\"\"\n",
    "                           , data=communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed485542-0fa7-4a11-a83c-16e85cfaa02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j_driver.execute_query(tools.import_community_query, data=communities)\n",
    "print(f\"Nodes created: {result.summary.counters.nodes_created}\")\n",
    "print(f\"Relationships created: {result.summary.counters.relationships_created}\")\n",
    "print(f\"Properties set: {result.summary.counters.properties_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c363b-822b-4eb4-a4bd-3c0b6b0fa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"MATCH (c:__Community__)\n",
    "WITH c, count {(c)<-[:IN_COMMUNITY]-()} AS size\n",
    "ORDER BY size DESC LIMIT 1\n",
    "RETURN c.title AS title, c.summary AS summary\n",
    "\"\"\"\n",
    ")\n",
    "print(data[0][\"title\"])\n",
    "print(data[0][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58115fda-82ee-40fa-a58d-eac722f1f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_retriever(query: str, rating_threshold: float = 5) -> str:\n",
    "    community_data, _, _ = neo4j_driver.execute_query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.rating >= $rating\n",
    "    RETURN c.summary AS summary\n",
    "    \"\"\",\n",
    "        rating=rating_threshold,\n",
    "    )\n",
    "    print(f\"Got {len(community_data)} community summaries\")\n",
    "    intermediate_results = []\n",
    "    for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "        intermediate_messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": tools.get_map_system_prompt(community[\"summary\"]),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            },\n",
    "        ]\n",
    "        intermediate_response = chat(intermediate_messages, model=\"gpt-4o\")\n",
    "        intermediate_results.append(intermediate_response)\n",
    "\n",
    "    final_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": tools.get_reduce_system_prompt(intermediate_results),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    summary = chat(final_messages, model=\"gpt-4o\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2d347-03b0-4aef-85c1-09c2259e194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_retriever(\"What is this story about?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021f02e-283a-4b75-85dc-2d32de31b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities, _, _ = neo4j_driver.execute_query(\n",
    "    \"\"\"\n",
    "MATCH (e:__Entity__)\n",
    "RETURN e.summary AS summary, e.name AS name\n",
    "\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d8c98-55c0-4382-9d47-79262a341f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45f6d3-2b82-4b8f-8975-380881f17c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"name\": el[\"name\"], \"embedding\": embed(el[\"summary\"])} for el in entities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8f04d-3f3b-4d0e-8b31-aeee41e70e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef293be8-b560-41e1-aefe-e9714b7ca98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver.execute_query(\n",
    "    \"\"\"\n",
    "UNWIND $data AS row\n",
    "MATCH (e:__Entity__ {name: row.name})\n",
    "CALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\n",
    "\"\"\",\n",
    "    data=data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdc323-a1c4-44e9-bf09-2514a6fa6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver.execute_query(\n",
    "    \"\"\"\n",
    "CREATE VECTOR INDEX entities IF NOT EXISTS\n",
    "FOR (n:__Entity__)\n",
    "ON (n.embedding)\n",
    "\"\"\",\n",
    "    data=data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587cbc2-7651-4958-b459-87dfc82f46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embedding values (first few dimensions)\n",
    "result = neo4j_driver.execute_query(\n",
    "    \"MATCH (e:__Entity__) WHERE e.embedding IS NOT NULL RETURN e.name, e.embedding[0..3] as first_dims LIMIT 3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe45c0-b404-43fe-93e6-d3673d997554",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0895bdd-9de0-409c-b09e-cb48af4cae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search_query = \"\"\"\n",
    "CALL db.index.vector.queryNodes('entities', $k, $embedding)\n",
    "YIELD node, score\n",
    "WITH collect(node) as nodes\n",
    "WITH collect {\n",
    "    UNWIND nodes as n\n",
    "    MATCH (n)<-[:HAS_ENTITY]->(c:__Chunk__)\n",
    "    WITH c, count(distinct n) as freq\n",
    "    RETURN c.text AS chunkText\n",
    "    ORDER BY freq DESC\n",
    "    LIMIT $topChunks\n",
    "} AS text_mapping,\n",
    "collect {\n",
    "    UNWIND nodes as n\n",
    "    MATCH (n)-[:IN_COMMUNITY]->(c:__Community__)\n",
    "    WITH c, c.rank as rank, c.weight AS weight\n",
    "    RETURN c.summary \n",
    "    ORDER BY rank, weight DESC\n",
    "    LIMIT $topCommunities\n",
    "} AS report_mapping,\n",
    "collect {\n",
    "    UNWIND nodes as n\n",
    "    MATCH (n)-[r:SUMMARIZED_RELATIONSHIP]-(m) \n",
    "    WHERE m IN nodes\n",
    "    RETURN r.summary AS descriptionText\n",
    "    ORDER BY r.rank, r.weight DESC \n",
    "    LIMIT $topInsideRels\n",
    "} as insideRels,\n",
    "collect {\n",
    "    UNWIND nodes as n\n",
    "    RETURN n.summary AS descriptionText\n",
    "} as entities\n",
    "RETURN {Chunks: text_mapping, Reports: report_mapping, \n",
    "       Relationships: insideRels, \n",
    "       Entities: entities} AS text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0487950-50f8-45fe-a438-389000f40d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_entities = 5\n",
    "\n",
    "topChunks = 3\n",
    "topCommunities = 3\n",
    "topInsideRels = 3\n",
    "\n",
    "\n",
    "def local_search(query: str) -> str:\n",
    "    context, _, _ = neo4j_driver.execute_query(\n",
    "        local_search_query,\n",
    "        embedding=embed(query),\n",
    "        topChunks=topChunks,\n",
    "        topCommunities=topCommunities,\n",
    "        topInsideRels=topInsideRels,\n",
    "        k=k_entities,\n",
    "    )\n",
    "    context_str = str(context[0][\"text\"])\n",
    "    local_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": tools.get_local_system_prompt(context_str),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query,\n",
    "        },\n",
    "    ]\n",
    "    final_answer = chat(local_messages, model=\"gpt-4o\")\n",
    "    return final_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110123e-017f-4389-9dd7-4d4f381a1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_search(\"Who is Ulysses?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddefe69-cad6-4d90-9187-f4472b9c28a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308c142-3ecb-4f88-923c-ed4db598319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4f90f-3fc6-4108-8434-aca60c8390c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ae10f-6d1b-49b1-9728-7462aad3d960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
